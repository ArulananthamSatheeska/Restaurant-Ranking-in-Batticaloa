{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37d8b8c4-4f26-4927-b296-68f1dcd09604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae63844d-b0e4-4958-9a96-c62efb7497be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Huawei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK data if needed\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e425c172-5db3-493c-aad9-532076bc2954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lines(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"File not found: {filename}\")\n",
    "        return []\n",
    "    with open(filename, 'r', encoding=\"utf-8\") as fp:\n",
    "        return fp.readlines()\n",
    "\n",
    "# Load custom stopwords from your file (e.g., 'custom_stopwords.txt')\n",
    "stop_words = read_lines(\"emotion/stopwords/stopwords.txt\")\n",
    "stop_words = [s.strip().lower() for s in stop_words]  # Clean up the stopwords\n",
    "    \n",
    "# Function to cut words from sentences and remove stopwords\n",
    "def cutword(x):\n",
    "    seg = nltk.word_tokenize(x)  # Use nltk to tokenize the input text\n",
    "    new_seg = []\n",
    "    for key in seg:\n",
    "        if not (key.strip().lower() in stop_words) and (len(key.strip()) > 1):\n",
    "            new_seg.append(key)\n",
    "    return new_seg\n",
    "    \n",
    "\n",
    "def cut_sentence(words):\n",
    "    start = 0\n",
    "    i = 0\n",
    "    token = 'meaningless'\n",
    "    sents = []\n",
    "    punt_list = ',.!?;~，。！？；～… '  # Punctuation list\n",
    "    for word in words:\n",
    "        if word not in punt_list:\n",
    "            i += 1\n",
    "            token = list(words[start:i + 2]).pop()\n",
    "        elif word in punt_list and token in punt_list:\n",
    "            i += 1\n",
    "            token = list(words[start:i + 2]).pop()\n",
    "        else:\n",
    "            sents.append(words[start:i + 1])  # Save sentence\n",
    "            start = i + 1\n",
    "            i += 1\n",
    "    if start < len(words):\n",
    "        sents.append(words[start:])\n",
    "    return sents\n",
    "\n",
    "\n",
    "def read_lines(filename):\n",
    "    fp = open(filename, 'r', encoding=\"utf-8\")\n",
    "    lines = []\n",
    "    for line in fp.readlines():\n",
    "        line = line.strip()\n",
    "        line = line\n",
    "        lines.append(line)\n",
    "    return lines\n",
    "\n",
    "\n",
    "def del_stopwords(seg_sent):\n",
    "    stopwords = read_lines(\"emotion/stopwords/stopwords.txt\")  \n",
    "    new_sent = []   \n",
    "    for word in seg_sent:\n",
    "        if word in stopwords:\n",
    "            continue\n",
    "        else:\n",
    "            new_sent.append(word)\n",
    "    return new_sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c9045aa-c5cb-4ef8-b710-946086437bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the positive and negative word lists\n",
    "posdict = read_lines(\"emotion/postive/positive.txt\")\n",
    "negdict = read_lines(\"emotion/negative/negative.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "509a5aef-baa2-4d33-bb1d-4186649862d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to match sentiment values based on words\n",
    "def match(word, sentiment_value):\n",
    "    if word in posdict:\n",
    "        sentiment_value *= 1\n",
    "    elif word in negdict:\n",
    "        sentiment_value *= -1\n",
    "    return sentiment_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be49dfb5-eb38-416b-9595-defbf2e38acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform sentiment scores\n",
    "def transform_to_positive_num(poscount, negcount):\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    if poscount < 0 and negcount >= 0:\n",
    "        neg_count += negcount - poscount\n",
    "        pos_count = 0\n",
    "    elif negcount < 0 and poscount >= 0:\n",
    "        pos_count = poscount - negcount\n",
    "        neg_count = 0\n",
    "    elif poscount < 0 and negcount < 0:\n",
    "        neg_count = -poscount\n",
    "        pos_count = -negcount\n",
    "    else:\n",
    "        pos_count = poscount\n",
    "        neg_count = negcount\n",
    "    total_count = pos_count + neg_count\n",
    "    return (pos_count, neg_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99db0f10-0753-407f-a999-6e75a5a08fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate sentiment score for a single review\n",
    "def single_review_sentiment_score(content):\n",
    "    if not content:  # Check if the input content is empty\n",
    "        return 0  # Return neutral score\n",
    "\n",
    "    if not isinstance(content, str) or not content.strip():  # Check if content is a string and not empty\n",
    "        return 0  # Return neutral score for empty or non-string content\n",
    "        \n",
    "    single_review_senti_score = []\n",
    "    cuted_review = cut_sentence(content)  # Tokenize into sentences\n",
    "\n",
    "    for sent in cuted_review:\n",
    "        seg_sent = cutword(sent)  # Tokenize into words\n",
    "        seg_sent = del_stopwords(seg_sent)  # Remove stopwords\n",
    "\n",
    "        i = 0\n",
    "        s = 0\n",
    "        poscount = 0\n",
    "        negcount = 0\n",
    "\n",
    "        for word in seg_sent:\n",
    "            if word in posdict:\n",
    "                poscount += 1\n",
    "                for w in seg_sent[s:i]:\n",
    "                    poscount = match(w, poscount)\n",
    "                s = i + 1\n",
    "            elif word in negdict:\n",
    "                negcount += 1\n",
    "                for w in seg_sent[s:i]:\n",
    "                    negcount = match(w, negcount)\n",
    "                s = i + 1\n",
    "            elif word == \"!\" or word == \"!\":\n",
    "                for w2 in seg_sent[::-1]:\n",
    "                    if w2 in posdict:\n",
    "                        poscount += 2\n",
    "                        break\n",
    "                    elif w2 in negdict:\n",
    "                        negcount += 2\n",
    "                        break\n",
    "            i += 1\n",
    "        single_review_senti_score.append(transform_to_positive_num(poscount, negcount))\n",
    "    \n",
    "    pos_result, neg_result = 0, 0\n",
    "    for res1, res2 in single_review_senti_score:\n",
    "        pos_result += res1\n",
    "        neg_result += res2\n",
    "    result = pos_result - neg_result\n",
    "    result = round(result, 1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa3c82fc-d468-4ee5-89a6-a25a0b1c21d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze reviews from an Excel file\n",
    "def analyze_reviews(file_name, sheet_name='Sheet1'):\n",
    "    df = pd.read_excel(file_name, sheet_name=sheet_name)\n",
    "    reviews = df['Review'].tolist()\n",
    "\n",
    "    pos_list, neg_list, total_list = [], [], []\n",
    "    \n",
    "    for review in reviews:\n",
    "        score = single_review_sentiment_score(review)\n",
    "        total_list.append(score)\n",
    "        if score >= 0:\n",
    "            pos_list.append(score)\n",
    "        else:\n",
    "            neg_list.append(score)\n",
    "\n",
    "    pos_number = len(pos_list)\n",
    "    neg_number = len(neg_list)\n",
    "    total_number = pos_number + neg_number\n",
    "\n",
    "    pos_percentage = round(float(pos_number) / float(total_number) * 100, 2) if total_number != 0 else 0.0\n",
    "    neg_percentage = round(float(neg_number) / float(total_number) * 100, 2) if total_number != 0 else 0.0\n",
    "\n",
    "    result_dict = {\n",
    "        'pos_number': pos_number,\n",
    "        'neg_number': neg_number,\n",
    "        'pos_percentage': pos_percentage,\n",
    "        'neg_percentage': neg_percentage\n",
    "    }\n",
    "\n",
    "    return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd68689f-e59c-4c9b-8ad9-ff1accbfc8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to sort and compare restaurant reviews based on sentiment\n",
    "def rank_restaurants(restaurant_results):\n",
    "    # Sort the restaurants based on their positive sentiment percentage\n",
    "    sorted_restaurants = sorted(restaurant_results, key=lambda x: x['result']['pos_percentage'], reverse=True)\n",
    "    return sorted_restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24571f0e-5049-4220-b07b-01c6972e5fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_best_dish(file_name, sheet_name='Sheet1'):\n",
    "    # Load the Excel sheet into a DataFrame\n",
    "    df = pd.read_excel(file_name, sheet_name=sheet_name)\n",
    "    \n",
    "    # Assuming the best dishes are in a column called 'Recommended'\n",
    "    recommended_dishes = df['Recommended dishes'].dropna().tolist()  # Drop any empty values\n",
    "\n",
    "    # Return the first recommended dish as the best dish (adjust logic if needed)\n",
    "    if recommended_dishes:\n",
    "        return recommended_dishes[0]  # Return the top recommended dish\n",
    "    return \"No dish recommended\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfb15441-0e26-4522-821a-0c0ffa4d7b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the model\n",
    "def save_model(restaurant_results, filename='restaurant_model.pkl'):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(restaurant_results, f)\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(filename='restaurant_model.pkl'):\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a08d9414-352a-4971-ae10-b1bbb5c6db45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the reviews for all restaurants\n",
    "def analyze_all_restaurants():\n",
    "    restaurants = [\n",
    "        {\"name\": \"Hajiyar Hotel\", \"file_name\": \"restaurants_data/Hajiyar Hotel/Hajiyar Hotel.xlsx\"},\n",
    "        {\"name\": \"Kiri Bhojan Restaurant\", \"file_name\": \"restaurants_data/Kiri Bhojan Restaurant/Kiri Bhojan_Restaurant.xlsx\"},\n",
    "        {\"name\": \"Six Flav Kitchen\", \"file_name\": \"restaurants_data/Six Flav Kitchen/Six Flav_Kitchen.xlsx\"},\n",
    "        {\"name\": \"Sri Krishna Cafe\", \"file_name\": \"restaurants_data/Sri Krishna cafe/Sri Krishna_Cafe.xlsx\"},\n",
    "        {\"name\": \"Sunshine\", \"file_name\": \"restaurants_data/Sunshine/Sunshine.xlsx\"}\n",
    "    ]\n",
    "\n",
    "    restaurant_results = []\n",
    "\n",
    "    for restaurant in restaurants:\n",
    "        result = analyze_reviews(restaurant['file_name'])\n",
    "        best_dish = extract_best_dish(restaurant['file_name'])\n",
    "        restaurant['result'] = result\n",
    "        restaurant['best_dish'] = best_dish\n",
    "        restaurant_results.append(restaurant)\n",
    "\n",
    "    return restaurant_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4c11bc6-de7f-4628-89b1-0a396d7af658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_restaurant_data(restaurant_name, new_review, new_recommended_dish, restaurant_results):\n",
    "    restaurant = next((r for r in restaurant_results if r['name'] == restaurant_name), None)\n",
    "\n",
    "    if restaurant:\n",
    "        # Load the existing data from the Exacel file\n",
    "        df = pd.read_excel(restaurant['file_name'])\n",
    "        \n",
    "        # Calculate the sentiment score for the new review\n",
    "        score = single_review_sentiment_score(new_review)\n",
    "        sentiment = 1 if score >= 0 else -1  # Set sentiment as 1 for positive, -1 for negative\n",
    "        \n",
    "        # Create a new row with the review, recommended dish, and sentiment\n",
    "        new_row = pd.DataFrame({\n",
    "            \"Review\": [new_review],\n",
    "            \"Recommended dishes\": [new_recommended_dish],\n",
    "            \"Sentiment\": [sentiment]\n",
    "        })\n",
    "        \n",
    "        # Concatenate the new row to the existing DataFrame\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "        \n",
    "        # Save the updated DataFrame back to the Excel file\n",
    "        df.to_excel(restaurant['file_name'], index=False)\n",
    "        \n",
    "        # Recalculate the sentiment analysis and update the results\n",
    "        updated_result = analyze_reviews(restaurant['file_name'])\n",
    "        updated_best_dish = extract_best_dish(restaurant['file_name'])\n",
    "        \n",
    "        # Update the restaurant's result and best dish in the restaurant_results list\n",
    "        restaurant['result'] = updated_result\n",
    "        restaurant['best_dish'] = updated_best_dish\n",
    "\n",
    "        print(f\"Restaurant '{restaurant_name}' has been updated with the new review, recommended dish, and sentiment.\")\n",
    "    else:\n",
    "        print(f\"Restaurant '{restaurant_name}' not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c53099f-ba50-479d-b5c9-2fb66de0db4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-rank the restaurants after updating data\n",
    "def rerank_restaurants(restaurant_results):\n",
    "    sorted_restaurants = rank_restaurants(restaurant_results)\n",
    "\n",
    "    print(\"\\n--- Updated Restaurant Rankings ---\")\n",
    "    for idx, restaurant in enumerate(sorted_restaurants, start=1):\n",
    "        print(f\"{idx}. {restaurant['name']} - Positive Sentiment: {restaurant['result']['pos_percentage']}% - Best Dish: {restaurant['best_dish']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7f88a4f-520c-4888-8c4a-2db7fa15e688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated user input\n",
    "def get_user_input():\n",
    "    print(\"\\n--- Update Restaurant Data ---\")\n",
    "    restaurant_name = input(\"Enter restaurant name (Hajiyar Hotel, Kiri Bhojan Restaurant, Six Flav Kitchen, Sri Krishna Cafe, Sunshine): \")\n",
    "    new_review = input(\"Enter your review: \")\n",
    "    new_recommended_dish = input(\"Enter your recommended dish: \")\n",
    "    return restaurant_name, new_review, new_recommended_dish\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e322c167-dbbe-47a2-aee8-63f59b3571e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initial Restaurant Rankings ---\n",
      "\n",
      "--- Updated Restaurant Rankings ---\n",
      "1. Sri Krishna Cafe - Positive Sentiment: 90.32% - Best Dish: Vada, Masala Dosa, Ulundu Vadai, Curd Vadai\n",
      "2. Kiri Bhojan Restaurant - Positive Sentiment: 86.67% - Best Dish: Mongolian rice, noodles\n",
      "3. Six Flav Kitchen - Positive Sentiment: 84.19% - Best Dish: Kottu, rice, biriyani,noodles,soup, fresh juice\n",
      "4. Hajiyar Hotel - Positive Sentiment: 83.94% - Best Dish: Hajiyar Special Shawal, Hajiyar Special Meal\n",
      "5. Sunshine - Positive Sentiment: 75.94% - Best Dish: Seafood Fried Rice, Tandoori Chicken, Chicken Briyani\n",
      "\n",
      "--- Update Restaurant Data ---\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter restaurant name (Hajiyar Hotel, Kiri Bhojan Restaurant, Six Flav Kitchen, Sri Krishna Cafe, Sunshine):  Kiri Bhojan Restaurant\n",
      "Enter your review:  The food was bland and overcooked, leaving me disappointed with my dining experience overall.\n",
      "Enter your recommended dish:  Normal rice and curry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant 'Kiri Bhojan Restaurant' has been updated with the new review, recommended dish, and sentiment.\n",
      "\n",
      "--- Updated Restaurant Rankings ---\n",
      "1. Sri Krishna Cafe - Positive Sentiment: 90.32% - Best Dish: Vada, Masala Dosa, Ulundu Vadai, Curd Vadai\n",
      "2. Kiri Bhojan Restaurant - Positive Sentiment: 86.26% - Best Dish: Mongolian rice, noodles\n",
      "3. Six Flav Kitchen - Positive Sentiment: 84.19% - Best Dish: Kottu, rice, biriyani,noodles,soup, fresh juice\n",
      "4. Hajiyar Hotel - Positive Sentiment: 83.94% - Best Dish: Hajiyar Special Shawal, Hajiyar Special Meal\n",
      "5. Sunshine - Positive Sentiment: 75.94% - Best Dish: Seafood Fried Rice, Tandoori Chicken, Chicken Briyani\n"
     ]
    }
   ],
   "source": [
    "# Main logic to run the recalculation based on user input\n",
    "def main():\n",
    "    # Load previous results if available\n",
    "    restaurant_results = load_model()\n",
    "    \n",
    "    if restaurant_results is None:\n",
    "        restaurant_results = analyze_all_restaurants()\n",
    "    \n",
    "    print(\"\\n--- Initial Restaurant Rankings ---\")\n",
    "    rerank_restaurants(restaurant_results)\n",
    "\n",
    "    # Get user input for restaurant update\n",
    "    restaurant_name, new_review, new_recommended_dish = get_user_input()\n",
    "    \n",
    "    # Update the restaurant data with new input and re-rank\n",
    "    update_restaurant_data(restaurant_name, new_review, new_recommended_dish, restaurant_results)\n",
    "    \n",
    "    # Recalculate rankings after the update\n",
    "    rerank_restaurants(restaurant_results)\n",
    "\n",
    "    # Save the updated model\n",
    "    save_model(restaurant_results)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d64dfb4-7be2-4cfd-8bd9-0b0f3f010256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Function to calculate accuracy for a specific file with restaurant name\n",
    "def calculate_accuracy_with_name(file_name, restaurant_name, sheet_name='Sheet1'):\n",
    "    # Load the Excel sheet into a DataFrame\n",
    "    df = pd.read_excel(file_name, sheet_name=sheet_name)\n",
    "    \n",
    "    # Drop rows with missing sentiment values\n",
    "    df = df.dropna(subset=['Sentiment'])\n",
    "    \n",
    "    # Extract reviews and actual sentiment labels from the DataFrame\n",
    "    reviews = df['Review'].tolist()\n",
    "    actual_sentiments = df['Sentiment'].tolist()  # Ensure there are no NaN values\n",
    "\n",
    "    predicted_sentiments = []\n",
    "\n",
    "    # Calculate sentiment score for each review and determine predicted sentiment\n",
    "    for review in reviews:\n",
    "        score = single_review_sentiment_score(review)\n",
    "        predicted_sentiment = 1 if score >= 0 else -1  # Use 1 for positive and -1 for negative\n",
    "        predicted_sentiments.append(predicted_sentiment)\n",
    "    \n",
    "    # Calculate the accuracy score\n",
    "    accuracy = accuracy_score(actual_sentiments, predicted_sentiments)\n",
    "    accuracy_percentage = round(accuracy * 100, 2)\n",
    "    \n",
    "    # Print the accuracy with the restaurant name\n",
    "    print(f\"Restaurant: {restaurant_name} - Model Accuracy: {accuracy_percentage}%\")\n",
    "    return accuracy_percentage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80f9a8db-d820-43e1-be3d-48de452f74ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant: Hajiyar Hotel - Model Accuracy: 77.98%\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "file_name = \"restaurants_data/Hajiyar Hotel/Hajiyar Hotel.xlsx\"  # Replace with your actual file path\n",
    "restaurant_name = \"Hajiyar Hotel\"  # Replace with the restaurant name\n",
    "accuracy = calculate_accuracy_with_name(file_name, restaurant_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be783a01-6b75-4f98-8071-f02c937b0dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant: Kiri Bhojan Restaurant - Model Accuracy: 82.94%\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "file_name = \"restaurants_data/Kiri Bhojan Restaurant/Kiri Bhojan_Restaurant.xlsx\"  # Replace with your actual file path\n",
    "restaurant_name = \"Kiri Bhojan Restaurant\"  # Replace with the restaurant name\n",
    "accuracy = calculate_accuracy_with_name(file_name, restaurant_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "599e671a-3244-41ba-a368-584180074888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant: Six Flav Kitchen - Model Accuracy: 80.93%\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "file_name = \"restaurants_data/Six Flav Kitchen/Six Flav_Kitchen.xlsx\"  # Replace with your actual file path\n",
    "restaurant_name = \"Six Flav Kitchen\"  # Replace with the restaurant name\n",
    "accuracy = calculate_accuracy_with_name(file_name, restaurant_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd8fb674-14ce-402f-9949-8ee5ead8030a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant: Sri Krishna Cafe - Model Accuracy: 88.48%\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "file_name = \"restaurants_data/Sri Krishna cafe/Sri Krishna_Cafe.xlsx\"  # Replace with your actual file path\n",
    "restaurant_name = \"Sri Krishna Cafe\"  # Replace with the restaurant name\n",
    "accuracy = calculate_accuracy_with_name(file_name, restaurant_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99819d08-60cc-4ed6-b125-9c65be192153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant: Sunshine - Model Accuracy: 68.87%\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "file_name = \"restaurants_data/Sunshine/Sunshine.xlsx\"  # Replace with your actual file path\n",
    "restaurant_name = \"Sunshine\"  # Replace with the restaurant name\n",
    "accuracy = calculate_accuracy_with_name(file_name, restaurant_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79245ab3-8146-42e8-becb-e0743ab1f642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
